<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>TrashNet | Saurabh</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="TrashNet" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Smart Trash Detection for Better Recycling" />
<meta property="og:description" content="Smart Trash Detection for Better Recycling" />
<link rel="canonical" href="https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html" />
<meta property="og:url" content="https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html" />
<meta property="og:site_name" content="Saurabh" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-23T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-06-23T00:00:00-05:00","headline":"TrashNet","description":"Smart Trash Detection for Better Recycling","mainEntityOfPage":{"@type":"WebPage","@id":"https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html"},"@type":"BlogPosting","url":"https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html","dateModified":"2020-06-23T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jsaurabh.dev/feed.xml" title="Saurabh" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-150018830-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>TrashNet | Saurabh</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="TrashNet" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Smart Trash Detection for Better Recycling" />
<meta property="og:description" content="Smart Trash Detection for Better Recycling" />
<link rel="canonical" href="https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html" />
<meta property="og:url" content="https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html" />
<meta property="og:site_name" content="Saurabh" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-23T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-06-23T00:00:00-05:00","headline":"TrashNet","description":"Smart Trash Detection for Better Recycling","mainEntityOfPage":{"@type":"WebPage","@id":"https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html"},"@type":"BlogPosting","url":"https://jsaurabh.dev/cv/object-detection/insight/2020/06/23/trashnet.html","dateModified":"2020-06-23T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://jsaurabh.dev/feed.xml" title="Saurabh" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-150018830-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Saurabh</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a><a class="page-link" href="/trashnet/">TrashNet</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">TrashNet</h1><p class="page-description">Smart Trash Detection for Better Recycling</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-23T00:00:00-05:00" itemprop="datePublished">
        Jun 23, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#cv">cv</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#object-detection">object-detection</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#insight">insight</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/jsaurabh/blog/tree/master/_notebooks/2020-06-23-trashnet.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Background">Background </a>
<ul>
<li class="toc-entry toc-h2"><a href="#CleanRobotics-and-TrashBot">CleanRobotics and TrashBot </a></li>
<li class="toc-entry toc-h2"><a href="#Dataset">Dataset </a></li>
<li class="toc-entry toc-h2"><a href="#Edge-Deployment">Edge Deployment </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#TrashNet">TrashNet </a>
<ul>
<li class="toc-entry toc-h2"><a href="#EfficientDet">EfficientDet </a>
<ul>
<li class="toc-entry toc-h3"><a href="#EfficientNet-backbone">EfficientNet backbone </a></li>
<li class="toc-entry toc-h3"><a href="#Building-from-EfficientNet">Building from EfficientNet </a></li>
<li class="toc-entry toc-h3"><a href="#BiFPN">BiFPN </a></li>
<li class="toc-entry toc-h3"><a href="#TrashNet---EfficientDet">TrashNet - EfficientDet </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#SSD-MobileNet-v2">SSD MobileNet v2 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Training">Training </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Class-Imbalance">Class Imbalance </a></li>
<li class="toc-entry toc-h2"><a href="#Pipeline">Pipeline </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Visualizing-Predictions">Visualizing Predictions </a></li>
<li class="toc-entry toc-h1"><a href="#Evaluation-and-Results">Evaluation and Results </a></li>
<li class="toc-entry toc-h1"><a href="#Learn-More">Learn More </a></li>
<li class="toc-entry toc-h1"><a href="#Footnotes">Footnotes </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-23-trashnet.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Background">
<a class="anchor" href="#Background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background<a class="anchor-link" href="#Background"> </a>
</h1>
<p>Trash Recycling is a big problem in the United States alone. Every year, millinos of tons of trash is produced, a lot of which is recyclable. We're losing upwards of 75% of recyclables every year, which end up in a landfill rather than being recycled. There's a huge opportunity to minimize waste and reclaim the value of these recyclables.</p>
<h2 id="CleanRobotics-and-TrashBot">
<a class="anchor" href="#CleanRobotics-and-TrashBot" aria-hidden="true"><span class="octicon octicon-link"></span></a>CleanRobotics and TrashBot<a class="anchor-link" href="#CleanRobotics-and-TrashBot"> </a>
</h2>
<p>TrashBot is a family of automated waste sorting bins produced by CleanRobotics. The idea behind TrashBot is to use the latest advances in AI and Computer Vision and Robotics to develop a product that can segregate trash more effectively than humans can.</p>
<p>CleanRobotics's current approach involves using single-class image classification to identify the trash items emptied into the TrashBot, and then use the underlying robotics to segregate it automatically. This leads to many problems, chief of which is not being able to do multi-class classification. You're also limited to only being to segregate one item at a time, severely impacting real world performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>This was a consulting project for the AI Fellowship at Insight Data Science, NY in partnership with CleanRobotics. Express permission has been obtained for any data, figures and results being talked about here. Deployment is internal to CleanRobotics, and screenshots on MS-COCO are used for demonstration where necessary.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset">
<a class="anchor" href="#Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset<a class="anchor-link" href="#Dataset"> </a>
</h2>
<p>As mentioned previously, the TrashBot currently works on an image classification model. The first task on the TODO list was to actually create a dataset suitable for object detection tasks. That meant going from per image label to per item bounding boxes and labels for items in each image in the dataset. I started by annotating the required ground truth boxes and class labels, creating an object detection dataset with roughly 8k images and upwards of 10k box annotations.</p>
<p>In total, there are 57 categories which make up the approximately 8k images. The range of objects per class if 7 at the lower end and upwards of 1300 at the higher end. The dataset is highly imbalanced, and I'll go into data augmentation and training time transforms below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Edge-Deployment">
<a class="anchor" href="#Edge-Deployment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Edge Deployment<a class="anchor-link" href="#Edge-Deployment"> </a>
</h2>
<p>In its current iteration, the network employed by the TrashBot captures the incoming data, processes it and sends it to the cloud for inference. This has proven to be a performance bottleneck, and the team is planning to move to edge inference to allow for faster decision making. The edge platform that CleanRobotics works on top of is the Google Coral, which is a hardware family built on top of EdgeTPUs designed by Google.</p>
<p>This brings alongwith it a set of challenges. First off, the model needs to be small enough to fit on the device itself. Secondly, the model needs to be TFLite and EdgeTPU compatible.</p>
<p>The EdgeTPU instruction set still doesn't support a lot of the core operations needed to implement a majority of the current state of the art in object detection. It's also restricted to TFLite, leaving Tensorflow as the framework of choice when it comes to development.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="TrashNet">
<a class="anchor" href="#TrashNet" aria-hidden="true"><span class="octicon octicon-link"></span></a>TrashNet<a class="anchor-link" href="#TrashNet"> </a>
</h1>
<p>Now that you have a sense of the task at hand, let me introduce the work I've done in this regard.</p>
<p>TrashNet is a collection of two models trained on the dataset described above. The first one is an EfficientDet, written in PyTorch, and the second one is an SSD MobileNet v2 model, trained using Tensorflow.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="EfficientDet">
<a class="anchor" href="#EfficientDet" aria-hidden="true"><span class="octicon octicon-link"></span></a>EfficientDet<a class="anchor-link" href="#EfficientDet"> </a>
</h2>
<p>EfficientDet is a family of object detection models that came out of Google Brain <sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup>. It is based on the EfficientNet paper, which achieves best in class performance on the image classification task.
EfficientDet has a scalable architecture while reducing the number of FLOPS by almost half and parameters by 10x.</p>
<p><img src="/images/copied_from_nb/../images/efficientdet.png" alt="EfficientDet architecture">
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>EfficientDet no longer SoTA as of 3rd June 2020.
</div>
<h3 id="EfficientNet-backbone">
<a class="anchor" href="#EfficientNet-backbone" aria-hidden="true"><span class="octicon octicon-link"></span></a>EfficientNet backbone<a class="anchor-link" href="#EfficientNet-backbone"> </a>
</h3>
<p>EfficientNet <sup id="fnref-2" class="footnote-ref"><a href="#fn-2">2</a></sup> aims to compound scale the network along multiple dimensions(width, depth and input resolution). Rather than only increasing one dimension at a time, EfficientNet expands the network along all dimensions. The authors use a compound scaling method to autmatically figure out the right scaling parameters, rather than manually turning the scaling coefficients.</p>
<h3 id="Building-from-EfficientNet">
<a class="anchor" href="#Building-from-EfficientNet" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building from EfficientNet<a class="anchor-link" href="#Building-from-EfficientNet"> </a>
</h3>
<p>EfficientDet builds on EfficientNet by adding a BiFPN(Bi-Directional Feature Pyramid Network) layer and a new compound scaling method to scale up the feature generation, resolution, backbone and the box/class prediction network.</p>
<h3 id="BiFPN">
<a class="anchor" href="#BiFPN" aria-hidden="true"><span class="octicon octicon-link"></span></a>BiFPN<a class="anchor-link" href="#BiFPN"> </a>
</h3>
<p>A BiFPN aims to aggregate multi-scale features in a top-down manner. Conventional top-down FPNs are limited by the one way information flow. The authors of PANet added an extra bottom-up aggregation network. This comes at an extra computation cost.</p>
<p>The authors proposed further optimizations to make bi-directional feature fusion feasible. First, they remove nodes with a single input edge. Secondly, if the input and output node are at the same level, they added an extra edge from input to output node to fuse more features. Thirdly, they repeat the bidirectional path multiple times to allow for better feature fusion. The figure below presents the journey from an FPN to a BiFPN</p>
<p><img src="/images/copied_from_nb/../images/bifpn.png" alt=""></p>

<pre><code>a. FPN top-down pathway for multi-scale feature fusion at levels 3-&gt;7 
b. PANet additional bottom-up pathway building on from FPNs
c. NAS-FPN Neural Architecture Search 
d. Expensive all to all feature generation
e. Simplified PANet by removing nodes with single input edge
f. BiFPN
</code></pre>
<p>For a review of Feature Pyramid Networks, check out this excellent introduction by Jonathan Hui on <a href="https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c">Medium</a></p>
<h3 id="TrashNet---EfficientDet">
<a class="anchor" href="#TrashNet---EfficientDet" aria-hidden="true"><span class="octicon octicon-link"></span></a>TrashNet - EfficientDet<a class="anchor-link" href="#TrashNet---EfficientDet"> </a>
</h3>
<p>This project only implements EfficientDet D0, foregoing compound scaling. After experimentation and trial runs using compound scaling, I found that EfficientDet D0 worked best. I hypothize this is because the dataset itself is small in size(roughly 8k images) and is highly imbalanced, leading to diminishing returns the more deeper the network got.</p>
<p>I use a pretrained EfficientNet backbone, trained on MS-COCO. This pretrained model is then used as the feature generator for the object detection task. The feature maps are then passed as inputs to the BiFPNs where they are fused together to learn multiple representations on the same input.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="SSD-MobileNet-v2">
<a class="anchor" href="#SSD-MobileNet-v2" aria-hidden="true"><span class="octicon octicon-link"></span></a>SSD MobileNet v2<a class="anchor-link" href="#SSD-MobileNet-v2"> </a>
</h2>
<p>Single Shot Detector networks, as their name suggests detect objects in a single shot. They don't do any kind of region proposals, nor do they mess around with feature fusion or input scaling.</p>
<p>Single Shot Detectors take a single pass for feature extraction. After going through a certain number of convolutions for feature extraction, you get a fixed number of bounding boxes for each location. The number of convolutions is dependent on the backbone network used for feature extraction.</p>
<p>MobileNets are the backbone network here and are used for feature generation. The output of a MobileNet is a high dimensional feature map, that then gets piped to a SSD detector via a 3x3 convolution.</p>
<p>MobileNet v2, again by the folks at Google, uses inverted residual blocks(with strides 1 and 2). MobileNets use bottleneck inputs and outputs and lightweight depthwise convolutions without non-linearities to maintain representational power.</p>
<p><img src="/images/copied_from_nb/../images/mobilenetv2.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>MobileNet v2 <sup id="fnref-3" class="footnote-ref"><a href="#fn-3">3</a></sup> also introduces shortcut connections between the bottleneck inputs, enabling faster training and better accuracy. Their high throughput and small footprint makes them especially suitable for devices with limited computing power.</p>
<p>As of today, SSD MobileNets are the only explicitly supported family of object detection models on the Google Coral making them a natural choice. For more information on models supported by Google Coral, click <a href="https://coral.ai/models/">here</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Training">
<a class="anchor" href="#Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training<a class="anchor-link" href="#Training"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Class-Imbalance">
<a class="anchor" href="#Class-Imbalance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Class Imbalance<a class="anchor-link" href="#Class-Imbalance"> </a>
</h2>
<p>As mentioned above, the dataset I am working with is highly imbalanced. There are multiple ways to deal with class imbalance, the simplest and most difficult of which is getting more data. This is not always feasible and usually expensive. However, it is definitely possible to synthesize more data and that's the approach I've taken.</p>
<p>After the dataset is built, a round of data augmentation is performed that uses image transforms such as flipping, scaling, rotation etc to generate different views of the ground truth data. I also go ahead and generate the ground truth bounding boxes necessary as we're dealing with an object detection problem.</p>
<figure>
    <div style="display:flex">
        <div style="flex">
            <figure>

<figure>
  
    <img class="docimage" src="/images/copied_from_nb/../images/original.png" alt="">
    
    
</figure>

                <figcaption><center>Original Image</center></figcaption>
            </figure>
        </div>
        <div style="flex">
            <figure>

<figure>
  
    <img class="docimage" src="/images/copied_from_nb/../images/augmented.png" alt="">
    
    
</figure>

                <figcaption><center>Augmented Image</center></figcaption>
            </figure>
        </div>
    </div>

    <figcaption><center>Data Augmentation.  HorizontalFlip, Translate(x=0.2, y=0.2) and RandomRotate(-2, 2)</center>           </figcaption>

</figure>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pipeline">
<a class="anchor" href="#Pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pipeline<a class="anchor-link" href="#Pipeline"> </a>
</h2>
<p>To deal with class imbalance, the original dataset was selectively augmented using the data augmentation described above. Classes with an average number of occurrences &lt; 200 were randomly augmented till they had at least 200 images. Furthermore, there is an additional round of training time transformations that each image goes through.</p>
<p>For the EfficientDet network, the newly augmented dataset was passed through the training loop for 50 epochs on an AWS p2.xlarge GPU instance, with each epoch taking around 20 minutes on average. The data augmentation loop is highly randomized, with different runs of augmentation yielding different versions of the dataset.</p>
<p>For the SSD MobileNet v2 network, the data was first converted to the TFRecords format. The TFRecords data was then passed as the input to a pretrained SSD MobileNet model from the Google Coral models repository. The network was then trained for about 100000 steps(about 120 epochs) on an AWS t2.2xlarge CPU instance. The Tensorflow model was then exported to a TFLite EdgeTPU compatible model using Coral board developer tools.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>Google Coral has an EdgeTPU architecture and hence, training on GPUs is not an option.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Visualizing-Predictions">
<a class="anchor" href="#Visualizing-Predictions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualizing Predictions<a class="anchor-link" href="#Visualizing-Predictions"> </a>
</h1>
<p>To visually inspect the predictions obtained from the model, I wrote a simple webapp using Streamlit. It took only a couple hundred lines of Python code, looks beautiful and is easily extensible allowing for all different kinds of summarized data presentation. The app is currently being tested interanally by the CleanRobotics team and is on track to be deployed in the early weeks of July.</p>
<p><img src="/images/copied_from_nb/../images/streamlit.png" alt="">
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>The images in the screenshot above come from a subset of the MS-COCO dataset.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Evaluation-and-Results">
<a class="anchor" href="#Evaluation-and-Results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluation and Results<a class="anchor-link" href="#Evaluation-and-Results"> </a>
</h1>
<p>As stated above, the EfficientDet model gets an mAP score of 0.69 while the SSD MobileNet model gets an mAP score of 0.49. Stay tuned for a more detailed comparison.</p>
<p>For evaluation results using the COCO eval script, head to the project GitHub. The link can be found below.</p>
<p>Sample results:</p>
<figure>
    <div style="display:flex">
        <div style="flex">
            <figure>

<figure>
  
    <img class="docimage" src="/images/copied_from_nb/../images/paper-plate-input.jpg" alt="">
    
    
</figure>

                <figcaption><center>Input</center></figcaption>
            </figure>
        </div>
        <div style="flex">
            <figure>

<figure>
  
    <img class="docimage" src="/images/copied_from_nb/../images/paper-plate-det.jpeg" alt="">
    
    
</figure>

                <figcaption><center>Output</center></figcaption>
            </figure>
        </div>
    </div>

    <figcaption><center></center>           </figcaption>

</figure>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Learn-More">
<a class="anchor" href="#Learn-More" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learn More<a class="anchor-link" href="#Learn-More"> </a>
</h1>
<ol>
<li><a href="https://github.com/jsaurabh/TrashBot">GitHub</a></li>
<li><a href="https://trashbot.readthedocs.io">Documentation</a></li>
<li><a href="https://docs.google.com/presentation/d/167GgLBf8keuRCf2Qv2E8zKgHSIw5MxX14krTAIAuXcc">Slides</a></li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Footnotes">
<a class="anchor" href="#Footnotes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Footnotes<a class="anchor-link" href="#Footnotes"> </a>
</h1>
<p></p>
<div class="footnotes"><p id="fn-1">1. <a href="https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html">EfficientDet: Towards Scalable and Efficient Object Detection</a><a href="#fnref-1" class="footnote footnotes">↩</a></p></div>
<p></p>
<div class="footnotes"><p id="fn-2">2. <a href="https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html">EfficientNet: Improving Accuracy and Efficient through AutoML and Model Scaling</a><a href="#fnref-2" class="footnote footnotes">↩</a></p></div>
<p></p>
<div class="footnotes"><p id="fn-3">3. <a href="https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html">MobileNet v2</a><a href="#fnref-3" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="jsaurabh/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/cv/object-detection/insight/2020/06/23/trashnet.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Masters grad. Software Engineer. Mostly blog about neural nets and other cool projects.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/jsaurabh" title="jsaurabh"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/jsaurabh95" title="jsaurabh95"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/jsaurabh1995" title="jsaurabh1995"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
